{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a91116d3",
   "metadata": {},
   "source": [
    "Meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e354a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "BigQuery Pipeline with Gemini 1.5 Flash Judge - Meta Dataset\n",
    "Uses Gemini 1.5 Flash to evaluate Gemini Flash decisions on Meta dataset\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "from google.oauth2 import service_account\n",
    "import google.generativeai as genai\n",
    "from google.generativeai.types import HarmCategory, HarmBlockThreshold\n",
    "import json\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Any, Optional\n",
    "import traceback\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "import re\n",
    "import io\n",
    "from PIL import Image\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv('.env')\n",
    "\n",
    "# Configuration for Meta dataset with Gemini 1.5 Flash\n",
    "PROJECT_ID = \"scope3-dev\"\n",
    "DATASET_ID = \"research_bs_monitoring\"\n",
    "META_TABLE = \"BA_Meta_Ground_Truth\"  # Meta ground truth table\n",
    "RESULTS_TABLE = \"BA_Meta_Gemini_15_Flash_Judge_Results\"  # Results table for Gemini 1.5 Flash\n",
    "RESEARCH_BUCKET = os.getenv('RESEARCH_BUCKET', 'classification-research')\n",
    "GEMINI_MODEL_NAME = \"gemini-1.5-flash\"  # Gemini 1.5 Flash model\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "# Configure Gemini 1.5 Flash\n",
    "if GEMINI_API_KEY:\n",
    "    genai.configure(api_key=GEMINI_API_KEY)\n",
    "    print(\"‚úÖ Gemini 1.5 Flash configured successfully!\")\n",
    "else:\n",
    "    print(\"‚ùå ERROR: Please set your GEMINI_API_KEY environment variable\")\n",
    "    exit(1)\n",
    "\n",
    "# Initialize BigQuery client\n",
    "def initialize_bigquery_client() -> bigquery.Client:\n",
    "    \"\"\"Initialize BigQuery client with proper error handling\"\"\"\n",
    "    try:\n",
    "        client = bigquery.Client(project=PROJECT_ID)\n",
    "        \n",
    "        # Test the connection immediately\n",
    "        print(f\"üîß Testing BigQuery connection to {PROJECT_ID}...\")\n",
    "        \n",
    "        # Verify we can access the dataset\n",
    "        dataset = client.get_dataset(f\"{PROJECT_ID}.{DATASET_ID}\")\n",
    "        print(f\"‚úÖ BigQuery connection successful!\")\n",
    "        print(f\"   Project: {PROJECT_ID}\")\n",
    "        print(f\"   Dataset: {dataset.dataset_id}\")\n",
    "        print(f\"   Location: {dataset.location}\")\n",
    "        \n",
    "        return client\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå BigQuery initialization failed: {type(e).__name__}: {e}\")\n",
    "        print(f\"\\nüí° Troubleshooting steps:\")\n",
    "        print(f\"   1. Run: gcloud auth application-default login\")\n",
    "        print(f\"   2. Verify project ID: {PROJECT_ID}\")\n",
    "        print(f\"   3. Verify dataset exists: {DATASET_ID}\")\n",
    "        print(f\"   4. Check BigQuery permissions (Data Editor, Job User)\")\n",
    "        raise\n",
    "\n",
    "# Initialize clients globally\n",
    "client = initialize_bigquery_client()\n",
    "\n",
    "try:\n",
    "    storage_client = storage.Client(project=PROJECT_ID)\n",
    "    print(\"‚úÖ Storage client initialized for GCS access\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Storage client failed: {e}\")\n",
    "    storage_client = None\n",
    "\n",
    "# Initialize Gemini model\n",
    "gemini_model = genai.GenerativeModel(GEMINI_MODEL_NAME)\n",
    "print(f\"‚úÖ {GEMINI_MODEL_NAME} model initialized\")\n",
    "\n",
    "class Gemini15FlashJudgePipeline:\n",
    "    \"\"\"Pipeline using Gemini 1.5 Flash to judge Gemini Flash decisions for Meta dataset\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.api_call_count = 0\n",
    "        self.total_api_time = 0\n",
    "        self.total_input_tokens = 0\n",
    "        self.total_output_tokens = 0\n",
    "        self.successful_evaluations = 0\n",
    "        self.failed_evaluations = 0\n",
    "\n",
    "    def check_available_tables(self):\n",
    "        \"\"\"Check what tables are available in the dataset\"\"\"\n",
    "        try:\n",
    "            print(f\"üîç Checking available tables in {PROJECT_ID}.{DATASET_ID}...\")\n",
    "            \n",
    "            query = f\"\"\"\n",
    "            SELECT table_name, table_type, creation_time \n",
    "            FROM `{PROJECT_ID}.{DATASET_ID}.INFORMATION_SCHEMA.TABLES`\n",
    "            ORDER BY table_name\n",
    "            \"\"\"\n",
    "            \n",
    "            tables_df = client.query(query).to_dataframe()\n",
    "            print(f\"üìä Available tables:\")\n",
    "            for _, row in tables_df.iterrows():\n",
    "                print(f\"   - {row['table_name']} ({row['table_type']})\")\n",
    "            \n",
    "            return tables_df['table_name'].tolist()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Could not check tables: {e}\")\n",
    "            return []\n",
    "\n",
    "    def load_full_meta_dataset(self, limit: int = None) -> pd.DataFrame:\n",
    "        \"\"\"Load Meta dataset from BigQuery - Simplified without unused fields\"\"\"\n",
    "        \n",
    "        if limit:\n",
    "            print(f\"üì• Loading TEST Meta dataset ({limit} records) from {PROJECT_ID}.{DATASET_ID}.{META_TABLE}...\")\n",
    "        else:\n",
    "            print(f\"üì• Loading COMPLETE Meta dataset from {PROJECT_ID}.{DATASET_ID}.{META_TABLE}...\")\n",
    "        \n",
    "        # First, check available tables\n",
    "        available_tables = self.check_available_tables()\n",
    "        \n",
    "        # Simplified query using only Meta table\n",
    "        limit_clause = f\"LIMIT {limit}\" if limit else \"\"\n",
    "        query = f\"\"\"\n",
    "        SELECT \n",
    "            artifact_id,\n",
    "            artifact_json_gcs_url,\n",
    "            model_prompt,\n",
    "            correct_classification,\n",
    "            correct_reasoning,\n",
    "            source,\n",
    "            '{META_TABLE}' as data_source\n",
    "        FROM `{PROJECT_ID}.{DATASET_ID}.{META_TABLE}`\n",
    "        ORDER BY artifact_id\n",
    "        {limit_clause}\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            print(f\"‚è≥ Executing query to load {'test' if limit else 'full'} Meta dataset...\")\n",
    "            df = client.query(query).to_dataframe()\n",
    "            \n",
    "            if limit:\n",
    "                print(f\"‚úÖ Successfully loaded TEST Meta dataset!\")\n",
    "                print(f\"üìä Test records: {len(df):,} (requested: {limit})\")\n",
    "            else:\n",
    "                print(f\"‚úÖ Successfully loaded COMPLETE Meta dataset!\")\n",
    "                print(f\"üìä Total records: {len(df):,}\")\n",
    "            \n",
    "            print(f\"üìä Classification distribution: {df['correct_classification'].value_counts().to_dict()}\")\n",
    "            print(f\"üìä Source distribution: {df['source'].value_counts().to_dict()}\")\n",
    "            print(f\"üìä Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n",
    "            \n",
    "            return df\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading {'test' if limit else 'full'} Meta dataset: {type(e).__name__}: {e}\")\n",
    "            raise\n",
    "\n",
    "    def extract_gcs_path(self, url: str) -> tuple:\n",
    "        \"\"\"Extract bucket name and path from GCS URL\"\"\"\n",
    "        try:\n",
    "            if not isinstance(url, str) or url == 'nan' or not url.strip():\n",
    "                return None, None\n",
    "            \n",
    "            # Check for pandas NaN    \n",
    "            if pd.isna(url):\n",
    "                return None, None\n",
    "                \n",
    "            # Match gs://bucket-name/path format\n",
    "            match = re.match(r\"gs://([^/]+)/(.+)\", url.strip())\n",
    "            if match:\n",
    "                return match.group(1), match.group(2)\n",
    "            return None, None\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting GCS path from {url}: {e}\")\n",
    "            return None, None\n",
    "\n",
    "    def read_json_from_gcs(self, bucket_name: str, json_path: str) -> Optional[Dict]:\n",
    "        \"\"\"Read JSON artifact from GCS bucket\"\"\"\n",
    "        try:\n",
    "            bucket = storage_client.bucket(bucket_name)\n",
    "            blob = bucket.blob(json_path)\n",
    "            \n",
    "            if not blob.exists():\n",
    "                print(f\"JSON file not found: gs://{bucket_name}/{json_path}\")\n",
    "                return None\n",
    "                \n",
    "            json_content = blob.download_as_text()\n",
    "            return json.loads(json_content)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading JSON from GCS: {e}\")\n",
    "            return None\n",
    "\n",
    "    def load_artifact_content(self, row):\n",
    "        \"\"\"Load artifact content with retry logic\"\"\"\n",
    "        if not storage_client:\n",
    "            print(f\"‚ö†Ô∏è No storage client, using demo content for {row['artifact_id']}\")\n",
    "            return self.create_demo_content()\n",
    "        \n",
    "        max_retries = 3\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                # Try to load from artifact_json_gcs_url (primary method for Meta table)\n",
    "                if pd.notna(row.get('artifact_json_gcs_url')):\n",
    "                    gcs_url = row['artifact_json_gcs_url']\n",
    "                    if attempt == 0:\n",
    "                        print(f\"üì• Loading Meta content from GCS URL: {gcs_url}\")\n",
    "                    \n",
    "                    bucket_name, json_path = self.extract_gcs_path(gcs_url)\n",
    "                    if bucket_name and json_path:\n",
    "                        content = self.read_json_from_gcs(bucket_name, json_path)\n",
    "                        if content:\n",
    "                            if attempt == 0:\n",
    "                                print(f\"‚úÖ Successfully loaded Meta content for {row['artifact_id']}\")\n",
    "                            return content\n",
    "                        else:\n",
    "                            if attempt < max_retries - 1:\n",
    "                                print(f\"‚ö†Ô∏è Attempt {attempt + 1} failed to load Meta JSON, retrying...\")\n",
    "                                time.sleep(1)  # Brief pause before retry\n",
    "                                continue\n",
    "                    else:\n",
    "                        print(f\"‚ö†Ô∏è Could not parse Meta GCS URL: {gcs_url}\")\n",
    "                        break\n",
    "                \n",
    "                # If all retries fail, use demo content\n",
    "                if attempt == max_retries - 1:\n",
    "                    print(f\"‚ö†Ô∏è All {max_retries} attempts failed for {row['artifact_id']}, using demo content\")\n",
    "                    return self.create_demo_content()\n",
    "                    \n",
    "            except Exception as e:\n",
    "                if attempt < max_retries - 1:\n",
    "                    print(f\"‚ö†Ô∏è Attempt {attempt + 1} failed for {row['artifact_id']}: {e}, retrying...\")\n",
    "                    time.sleep(1)\n",
    "                    continue\n",
    "                else:\n",
    "                    print(f\"‚ö†Ô∏è All retries failed for {row['artifact_id']}: {e}, using demo content\")\n",
    "                    return self.create_demo_content()\n",
    "        \n",
    "        return self.create_demo_content()\n",
    "    \n",
    "    def create_demo_content(self):\n",
    "        \"\"\"Create demo content when GCS loading fails\"\"\"\n",
    "        return {\n",
    "            \"url\": \"https://example.com/content\",\n",
    "            \"text_content\": [\n",
    "                {\n",
    "                    \"type\": \"heading\",\n",
    "                    \"heading\": {\"level\": 1, \"text\": \"Sample Content\"}\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"paragraph\", \n",
    "                    \"paragraphs\": [\n",
    "                        \"This is sample content for demonstration purposes.\",\n",
    "                        \"It represents the type of content that would be evaluated for brand safety.\"\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    def extract_content_from_artifact(self, artifact_json: Dict) -> Dict[str, any]:\n",
    "        \"\"\"Extract text and image content from artifact JSON\"\"\"\n",
    "        content = {\n",
    "            'text_content': '',\n",
    "            'image_paths': [],\n",
    "            'has_image': False,\n",
    "            'content_type': 'unknown'\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            text_parts = []\n",
    "            \n",
    "            # Look for structured JSON content with text_content array (main approach)\n",
    "            text_content_array = artifact_json.get(\"text_content\", [])\n",
    "            if text_content_array and isinstance(text_content_array, list):\n",
    "                # Parse structured content\n",
    "                for content_item in text_content_array:\n",
    "                    if isinstance(content_item, dict):\n",
    "                        content_type = content_item.get(\"type\", \"\")\n",
    "                        \n",
    "                        if content_type == \"paragraph\":\n",
    "                            paragraphs = content_item.get(\"paragraphs\", [])\n",
    "                            if paragraphs:\n",
    "                                text_parts.extend(paragraphs)\n",
    "                        \n",
    "                        elif content_type == \"image\":\n",
    "                            image_data = content_item.get(\"image\", {})\n",
    "                            if isinstance(image_data, dict):\n",
    "                                image_identifier = image_data.get(\"filepath\", \"\")\n",
    "                                if image_identifier:\n",
    "                                    content['image_paths'].append(image_identifier)\n",
    "                                    content['has_image'] = True\n",
    "                                \n",
    "                                # Also extract alt_text for context\n",
    "                                alt_text = image_data.get(\"alt_text\", \"\")\n",
    "                                if alt_text:\n",
    "                                    text_parts.append(f\"[Image: {alt_text}]\")\n",
    "                        \n",
    "                        elif content_type == \"video\":\n",
    "                            video_data = content_item.get(\"video\", {})\n",
    "                            if isinstance(video_data, dict):\n",
    "                                frames = video_data.get(\"frames\", [])\n",
    "                                if frames and len(frames) > 0:\n",
    "                                    # Use first frame as representative image\n",
    "                                    first_frame = frames[0] if isinstance(frames[0], dict) else {}\n",
    "                                    frame_identifier = first_frame.get(\"filepath\", \"\")\n",
    "                                    if frame_identifier:\n",
    "                                        content['image_paths'].append(frame_identifier)\n",
    "                                        content['has_image'] = True\n",
    "                    \n",
    "                    elif isinstance(content_item, str):\n",
    "                        # Handle direct string content\n",
    "                        text_parts.append(content_item)\n",
    "            \n",
    "            # Fallback to legacy format if no structured content found\n",
    "            if not text_parts and not content['has_image']:\n",
    "                # Common text fields\n",
    "                for field in ['title', 'description', 'caption', 'text', 'content', 'body']:\n",
    "                    if field in artifact_json and artifact_json[field]:\n",
    "                        text_parts.append(str(artifact_json[field]))\n",
    "                \n",
    "                # Legacy image fields\n",
    "                legacy_content = artifact_json.get(\"text_content\", \"\")\n",
    "                if isinstance(legacy_content, str):\n",
    "                    text_parts.append(legacy_content)\n",
    "                    \n",
    "                    # Look for image identifiers in the text using regex - FIXED VERSION\n",
    "                    image_pattern = r'[a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{12}\\.(?:jpg|jpeg|png|webp|avif)'\n",
    "                    image_matches = re.findall(image_pattern, legacy_content)\n",
    "                    if image_matches:\n",
    "                        # Use the first full match (complete UUID + extension)\n",
    "                        content['image_paths'].append(image_matches[0])\n",
    "                        content['has_image'] = True\n",
    "                \n",
    "                # Platform-specific extraction\n",
    "                if 'platform_data' in artifact_json:\n",
    "                    platform_data = artifact_json['platform_data']\n",
    "                    if isinstance(platform_data, dict):\n",
    "                        for key, value in platform_data.items():\n",
    "                            if isinstance(value, str) and value.strip():\n",
    "                                text_parts.append(value)\n",
    "                \n",
    "                # Legacy image URL fields\n",
    "                image_fields = ['image_url', 'image_path', 'media_url', 'thumbnail_url']\n",
    "                for field in image_fields:\n",
    "                    if field in artifact_json and artifact_json[field]:\n",
    "                        content['image_paths'].append(artifact_json[field])\n",
    "                        content['has_image'] = True\n",
    "            \n",
    "            # Combine all text content\n",
    "            content['text_content'] = ' '.join(text_parts).strip()\n",
    "            \n",
    "            # Determine content type\n",
    "            if content['has_image'] and content['text_content']:\n",
    "                content['content_type'] = 'multimodal'\n",
    "            elif content['has_image']:\n",
    "                content['content_type'] = 'image_only'\n",
    "            elif content['text_content']:\n",
    "                content['content_type'] = 'text_only'\n",
    "            else:\n",
    "                content['content_type'] = 'no_content'\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting content: {e}\")\n",
    "        \n",
    "        return content\n",
    "\n",
    "    def extract_source_context(self, content):\n",
    "        \"\"\"Extract text content from artifact\"\"\"\n",
    "        extracted_content = self.extract_content_from_artifact(content)\n",
    "        return extracted_content['text_content'] if extracted_content['text_content'] else \"Sample content for evaluation\"\n",
    "\n",
    "    def query_gemini_judge(self, content, brand_prompt, gemini_flash_verdict):\n",
    "        \"\"\"Query Gemini 1.5 Flash with retry logic\"\"\"\n",
    "        max_retries = 3\n",
    "        base_delay = 1\n",
    "        \n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                # Extract text content using the same method as your pipeline\n",
    "                source_context = self.extract_source_context(content)\n",
    "                \n",
    "                # Create judge prompt - Gemini 1.5 Flash evaluating Gemini Flash\n",
    "                judge_prompt = f\"\"\"You are an expert content moderator using Gemini 1.5 Flash to evaluate another AI model's (Gemini Flash) brand safety decision.\n",
    "\n",
    "Use your reasoning capabilities to provide a thorough analysis of whether Gemini Flash made the right decision.\n",
    "\n",
    "BRAND GUIDELINES:\n",
    "{brand_prompt}\n",
    "\n",
    "CONTENT TO EVALUATE:\n",
    "{source_context[:2000]}{\"...\" if len(source_context) > 2000 else \"\"}\n",
    "\n",
    "GEMINI FLASH'S VERDICT:\n",
    "{gemini_flash_verdict}\n",
    "\n",
    "As Gemini 1.5 Flash, evaluate whether Gemini Flash's verdict is correct and well-reasoned. Consider:\n",
    "1. Accuracy of the classification given the brand guidelines\n",
    "2. Quality and completeness of the reasoning provided\n",
    "3. Any nuances or edge cases that Flash may have missed\n",
    "4. Whether you would reach the same conclusion\n",
    "\n",
    "Respond in JSON format:\n",
    "{{\n",
    "  \"judge_agreement\": true/false,\n",
    "  \"confidence\": 0.0-1.0,\n",
    "  \"verdict\": \"Aligned\" or \"Not-Aligned\",\n",
    "  \"reasoning\": \"Your detailed analysis as Gemini 1.5 Flash of why Flash's decision was correct or incorrect\",\n",
    "  \"improvements\": [\"suggestions for better reasoning if disagreeing\"],\n",
    "  \"flash_analysis\": \"analysis of Flash's performance on this content\"\n",
    "}}\"\"\"\n",
    "                \n",
    "                # Configure safety settings\n",
    "                safety_settings = {\n",
    "                    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "                    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "                    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "                    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "                }\n",
    "                \n",
    "                # Make API call with Gemini 1.5 Flash\n",
    "                start_time = time.time()\n",
    "                response = gemini_model.generate_content(\n",
    "                    judge_prompt,\n",
    "                    safety_settings=safety_settings\n",
    "                )\n",
    "                api_time = time.time() - start_time\n",
    "                \n",
    "                # Update tracking\n",
    "                self.api_call_count += 1\n",
    "                self.total_api_time += api_time\n",
    "                \n",
    "                # Track tokens if available\n",
    "                if hasattr(response, 'usage_metadata'):\n",
    "                    self.total_input_tokens += response.usage_metadata.prompt_token_count\n",
    "                    self.total_output_tokens += response.usage_metadata.candidates_token_count\n",
    "                \n",
    "                if response.text:\n",
    "                    result = self.parse_gemini_response(response.text, api_time)\n",
    "                    result['model_used'] = GEMINI_MODEL_NAME\n",
    "                    result['attempts'] = attempt + 1\n",
    "                    return result\n",
    "                else:\n",
    "                    if attempt < max_retries - 1:\n",
    "                        delay = base_delay * (2 ** attempt)  # Exponential backoff\n",
    "                        print(f\"‚ö†Ô∏è Empty response, retrying in {delay}s... (attempt {attempt + 1}/{max_retries})\")\n",
    "                        time.sleep(delay)\n",
    "                        continue\n",
    "                    else:\n",
    "                        return {\n",
    "                            'error': f'Empty response from {GEMINI_MODEL_NAME} after {max_retries} attempts',\n",
    "                            'model_used': GEMINI_MODEL_NAME,\n",
    "                            'api_time': api_time,\n",
    "                            'attempts': max_retries\n",
    "                        }\n",
    "                        \n",
    "            except Exception as e:\n",
    "                if attempt < max_retries - 1:\n",
    "                    delay = base_delay * (2 ** attempt)  # Exponential backoff\n",
    "                    print(f\"‚ö†Ô∏è API error: {str(e)[:100]}..., retrying in {delay}s... (attempt {attempt + 1}/{max_retries})\")\n",
    "                    time.sleep(delay)\n",
    "                    continue\n",
    "                else:\n",
    "                    return {\n",
    "                        'error': f'Failed after {max_retries} attempts: {str(e)}',\n",
    "                        'model_used': GEMINI_MODEL_NAME,\n",
    "                        'api_time': 0,\n",
    "                        'attempts': max_retries\n",
    "                    }\n",
    "        \n",
    "        # Should never reach here, but just in case\n",
    "        return {\n",
    "            'error': f'Unexpected failure after {max_retries} attempts',\n",
    "            'model_used': GEMINI_MODEL_NAME,\n",
    "            'api_time': 0,\n",
    "            'attempts': max_retries\n",
    "        }\n",
    "\n",
    "    def parse_gemini_response(self, response_text, api_time):\n",
    "        \"\"\"Parse Gemini 1.5 Flash response\"\"\"\n",
    "        try:\n",
    "            # Clean the response - remove markdown code blocks if present\n",
    "            cleaned_text = response_text.strip()\n",
    "            if cleaned_text.startswith('```json'):\n",
    "                cleaned_text = cleaned_text.replace('```json', '').replace('```', '').strip()\n",
    "            elif cleaned_text.startswith('```'):\n",
    "                cleaned_text = cleaned_text.replace('```', '').strip()\n",
    "            \n",
    "            # Try to find JSON in response\n",
    "            if '{' in cleaned_text and '}' in cleaned_text:\n",
    "                start_idx = cleaned_text.find('{')\n",
    "                end_idx = cleaned_text.rfind('}') + 1\n",
    "                json_str = cleaned_text[start_idx:end_idx]\n",
    "                \n",
    "                parsed = json.loads(json_str)\n",
    "                \n",
    "                # Ensure would_reach_same_conclusion is present\n",
    "                would_reach_same = parsed.get('would_reach_same_conclusion')\n",
    "                if would_reach_same is None:\n",
    "                    # Try to infer from the text if not explicitly provided\n",
    "                    full_text = response_text.lower()\n",
    "                    if any(phrase in full_text for phrase in ['same conclusion', 'reach the same', 'would also classify', 'independent conclusion']):\n",
    "                        would_reach_same = True\n",
    "                    elif any(phrase in full_text for phrase in ['different conclusion', 'would not reach', 'disagree with classification']):\n",
    "                        would_reach_same = False\n",
    "                    else:\n",
    "                        # Default to same as judge_agreement if unclear\n",
    "                        would_reach_same = parsed.get('judge_agreement', None)\n",
    "                \n",
    "                return {\n",
    "                    'judge_agreement': parsed.get('judge_agreement', None),\n",
    "                    'confidence': parsed.get('confidence', 0.0),\n",
    "                    'verdict': parsed.get('verdict', 'Unknown'),\n",
    "                    'would_reach_same_conclusion': would_reach_same,\n",
    "                    'reasoning': parsed.get('reasoning', ''),\n",
    "                    'improvements': parsed.get('improvements', []),\n",
    "                    'flash_analysis': parsed.get('flash_analysis', ''),\n",
    "                    'raw_response': response_text,\n",
    "                    'api_time': api_time\n",
    "                }\n",
    "            else:\n",
    "                # Fallback parsing\n",
    "                agreement = any(word in response_text.lower() for word in ['agree', 'correct', 'accurate'])\n",
    "                same_conclusion = any(phrase in response_text.lower() for phrase in [\n",
    "                    'same conclusion', 'reach the same', 'would also', 'independent conclusion'\n",
    "                ])\n",
    "                return {\n",
    "                    'judge_agreement': agreement,\n",
    "                    'confidence': 0.5,\n",
    "                    'verdict': 'Aligned' if agreement else 'Not-Aligned', \n",
    "                    'would_reach_same_conclusion': same_conclusion if same_conclusion else agreement,\n",
    "                    'reasoning': response_text,\n",
    "                    'improvements': [],\n",
    "                    'flash_analysis': '',\n",
    "                    'raw_response': response_text,\n",
    "                    'api_time': api_time\n",
    "                }\n",
    "                \n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"‚ö†Ô∏è JSON parsing failed: {e}\")\n",
    "            print(f\"Raw text: {response_text[:200]}...\")\n",
    "            \n",
    "            agreement = any(word in response_text.lower() for word in ['agree', 'reasonable'])\n",
    "            # Try to infer would_reach_same_conclusion from text\n",
    "            same_conclusion = any(phrase in response_text.lower() for phrase in [\n",
    "                'same conclusion', 'reach the same', 'would also', 'agree with the verdict'\n",
    "            ])\n",
    "            return {\n",
    "                'judge_agreement': agreement,\n",
    "                'would_reach_same_conclusion': same_conclusion if same_conclusion else agreement,\n",
    "                'confidence': 0.5,\n",
    "                'verdict': 'Aligned' if agreement else 'Not-Aligned',\n",
    "                'reasoning': response_text,\n",
    "                'improvements': [],\n",
    "                'flash_analysis': '',\n",
    "                'raw_response': response_text,\n",
    "                'api_time': api_time\n",
    "            }\n",
    "\n",
    "    def run_full_dataset_evaluation(self, meta_df: pd.DataFrame, \n",
    "                                   batch_size: int = 100,\n",
    "                                   save_to_bigquery: bool = True) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Run Gemini 1.5 Flash evaluation on the COMPLETE Meta dataset\n",
    "        \"\"\"\n",
    "        \n",
    "        print(f\"üîÑ RUNNING GEMINI 1.5 FLASH EVALUATION ON FULL META DATASET\")\n",
    "        print(\"=\" * 70)\n",
    "        print(f\"üìä Total records to process: {len(meta_df):,}\")\n",
    "        print(f\"üì¶ Batch size: {batch_size:,}\")\n",
    "        print(f\"üì¶ Number of batches: {(len(meta_df) + batch_size - 1) // batch_size}\")\n",
    "        print(f\"üß† Judge model: {GEMINI_MODEL_NAME}\")\n",
    "        print(f\"‚ö° Flash model: Gemini Flash (from ground truth)\")\n",
    "        \n",
    "        # Initialize results storage\n",
    "        all_results = []\n",
    "        \n",
    "        # Process in batches\n",
    "        for batch_num in range(0, len(meta_df), batch_size):\n",
    "            batch_end = min(batch_num + batch_size, len(meta_df))\n",
    "            batch_df = meta_df.iloc[batch_num:batch_end].copy()\n",
    "            \n",
    "            batch_number = (batch_num // batch_size) + 1\n",
    "            total_batches = (len(meta_df) + batch_size - 1) // batch_size\n",
    "            \n",
    "            print(f\"\\nüîÑ Processing Batch {batch_number}/{total_batches}\")\n",
    "            print(f\"   Records: {batch_num + 1:,} to {batch_end:,}\")\n",
    "            print(f\"   Batch size: {len(batch_df):,}\")\n",
    "            \n",
    "            batch_start_time = time.time()\n",
    "            batch_results = []\n",
    "            batch_successful = 0\n",
    "            batch_failed = 0\n",
    "            \n",
    "            # Process each record in the batch with progress bar\n",
    "            for idx, row in tqdm(batch_df.iterrows(), total=len(batch_df), \n",
    "                               desc=f\"Batch {batch_number}\", leave=False):\n",
    "                \n",
    "                try:\n",
    "                    # Load artifact content using updated method\n",
    "                    content = self.load_artifact_content(row)\n",
    "                    \n",
    "                    # Get Gemini 1.5 Flash judgment of Flash's decision\n",
    "                    judge_result = self.query_gemini_judge(\n",
    "                        content, \n",
    "                        row['model_prompt'], \n",
    "                        row['correct_reasoning']\n",
    "                    )\n",
    "                    \n",
    "                    # Create result record\n",
    "                    result = {\n",
    "                        'artifact_id': str(row['artifact_id']),\n",
    "                        'data_source': str(row['data_source']),\n",
    "                        'source': str(row.get('source', 'unknown')),\n",
    "                        'flash_classification': int(row['correct_classification']),\n",
    "                        'flash_reasoning': str(row['correct_reasoning'])[:1000],  # Truncate for storage\n",
    "                        'model_prompt': str(row['model_prompt'])[:500],\n",
    "                        'judge_agreement': judge_result.get('judge_agreement', None),\n",
    "                        'verdict': str(judge_result.get('verdict', 'Unknown')),\n",
    "                        'confidence': float(judge_result.get('confidence', 0.0)),\n",
    "                        'would_reach_same_conclusion': judge_result.get('would_reach_same_conclusion', None),\n",
    "                        'reasoning': str(judge_result.get('reasoning', ''))[:1000],\n",
    "                        'flash_analysis': str(judge_result.get('flash_analysis', ''))[:500],\n",
    "                        'improvements': str('; '.join(judge_result.get('improvements', [])))[:500],\n",
    "                        'api_call_time': float(judge_result.get('api_time', 0.0)),\n",
    "                        'batch_number': int(batch_number),\n",
    "                        'created_at': pd.Timestamp.now(),\n",
    "                        'model_used': str(judge_result.get('model_used', GEMINI_MODEL_NAME)),\n",
    "                        'error_message': str(judge_result.get('error', '')) if 'error' in judge_result else None,\n",
    "                        'retry_attempts': int(judge_result.get('attempts', 1))\n",
    "                    }\n",
    "                    \n",
    "                    batch_results.append(result)\n",
    "                    batch_successful += 1\n",
    "                    self.successful_evaluations += 1\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Error processing {row['artifact_id']}: {e}\")\n",
    "                    batch_failed += 1\n",
    "                    self.failed_evaluations += 1\n",
    "                    continue\n",
    "            \n",
    "            batch_time = time.time() - batch_start_time\n",
    "            \n",
    "            # Calculate batch statistics\n",
    "            if batch_results:\n",
    "                batch_agreement_rate = sum(1 for r in batch_results \n",
    "                                         if r['judge_agreement'] is True) / len(batch_results)\n",
    "                batch_avg_confidence = np.mean([r['confidence'] for r in batch_results \n",
    "                                              if r['confidence'] > 0])\n",
    "            else:\n",
    "                batch_agreement_rate = 0\n",
    "                batch_avg_confidence = 0\n",
    "            \n",
    "            print(f\"   ‚úÖ Batch {batch_number} completed in {batch_time:.1f}s\")\n",
    "            print(f\"   üìä Successful: {batch_successful}, Failed: {batch_failed}\")\n",
    "            print(f\"   üìä Agreement rate: {batch_agreement_rate:.1%}\")\n",
    "            print(f\"   üìä Avg confidence: {batch_avg_confidence:.2f}\")\n",
    "            print(f\"   üìä API calls: {self.api_call_count}\")\n",
    "            \n",
    "            # Add batch results to overall results\n",
    "            all_results.extend(batch_results)\n",
    "            \n",
    "            # Save batch to BigQuery if requested\n",
    "            if save_to_bigquery and len(batch_results) > 0:\n",
    "                self.save_batch_to_bigquery(pd.DataFrame(batch_results), batch_number)\n",
    "        \n",
    "        # Convert all results to DataFrame\n",
    "        results_df = pd.DataFrame(all_results)\n",
    "        \n",
    "        # Final statistics\n",
    "        final_agreement_rate = results_df['judge_agreement'].mean() if len(results_df) > 0 else 0\n",
    "        final_avg_confidence = results_df['confidence'].mean() if len(results_df) > 0 else 0\n",
    "        total_api_time = results_df['api_call_time'].sum() if len(results_df) > 0 else 0\n",
    "        \n",
    "        print(f\"\\n‚úÖ GEMINI 1.5 FLASH EVALUATION COMPLETED!\")\n",
    "        print(f\"üìä Total records processed: {len(results_df):,}\")\n",
    "        print(f\"üìä Successful evaluations: {self.successful_evaluations}\")\n",
    "        print(f\"üìä Failed evaluations: {self.failed_evaluations}\")\n",
    "        print(f\"üìä Overall agreement rate: {final_agreement_rate:.1%}\")\n",
    "        print(f\"üìä Average confidence: {final_avg_confidence:.2f}\")\n",
    "        print(f\"üìä Total API calls: {self.api_call_count}\")\n",
    "        print(f\"üìä Total API time: {total_api_time:.1f}s ({total_api_time/60:.1f} minutes)\")\n",
    "        \n",
    "        # Cost estimation for Gemini 1.5 Flash (much cheaper than 2.5 Pro)\n",
    "        input_cost = self.total_input_tokens * 0.00000075  # Gemini 1.5 Flash pricing\n",
    "        output_cost = self.total_output_tokens * 0.0000015\n",
    "        total_cost = input_cost + output_cost\n",
    "        print(f\"üí∞ Estimated cost: ${total_cost:.4f}\")\n",
    "        print(f\"   Input tokens: {self.total_input_tokens:,} (${input_cost:.4f})\")\n",
    "        print(f\"   Output tokens: {self.total_output_tokens:,} (${output_cost:.4f})\")\n",
    "        \n",
    "        return results_df\n",
    "\n",
    "    def save_batch_to_bigquery(self, batch_df: pd.DataFrame, batch_number: int):\n",
    "        \"\"\"Save a batch of results to BigQuery with updated schema\"\"\"\n",
    "        print(f\"   üíæ Saving batch {batch_number} to BigQuery ({len(batch_df)} records)...\")\n",
    "        \n",
    "        try:\n",
    "            # Configure the load job\n",
    "            table_ref = f\"{PROJECT_ID}.{DATASET_ID}.{RESULTS_TABLE}\"\n",
    "            \n",
    "            job_config = bigquery.LoadJobConfig(\n",
    "                write_disposition=\"WRITE_APPEND\",  # Append data\n",
    "                create_disposition=\"CREATE_IF_NEEDED\",  # Create table if needed\n",
    "                schema=[\n",
    "                    bigquery.SchemaField(\"artifact_id\", \"STRING\", mode=\"REQUIRED\"),\n",
    "                    bigquery.SchemaField(\"data_source\", \"STRING\", mode=\"NULLABLE\"),\n",
    "                    bigquery.SchemaField(\"source\", \"STRING\", mode=\"NULLABLE\"),\n",
    "                    bigquery.SchemaField(\"flash_classification\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "                    bigquery.SchemaField(\"flash_reasoning\", \"STRING\", mode=\"NULLABLE\"),\n",
    "                    bigquery.SchemaField(\"model_prompt\", \"STRING\", mode=\"NULLABLE\"),\n",
    "                    bigquery.SchemaField(\"judge_agreement\", \"BOOLEAN\", mode=\"NULLABLE\"),\n",
    "                    bigquery.SchemaField(\"verdict\", \"STRING\", mode=\"NULLABLE\"),\n",
    "                    bigquery.SchemaField(\"confidence\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "                    bigquery.SchemaField(\"would_reach_same_conclusion\", \"BOOLEAN\", mode=\"NULLABLE\"),\n",
    "                    bigquery.SchemaField(\"reasoning\", \"STRING\", mode=\"NULLABLE\"),\n",
    "                    bigquery.SchemaField(\"flash_analysis\", \"STRING\", mode=\"NULLABLE\"),\n",
    "                    bigquery.SchemaField(\"improvements\", \"STRING\", mode=\"NULLABLE\"),\n",
    "                    bigquery.SchemaField(\"api_call_time\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "                    bigquery.SchemaField(\"batch_number\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "                    bigquery.SchemaField(\"created_at\", \"TIMESTAMP\", mode=\"NULLABLE\"),\n",
    "                    bigquery.SchemaField(\"model_used\", \"STRING\", mode=\"NULLABLE\"),\n",
    "                    bigquery.SchemaField(\"error_message\", \"STRING\", mode=\"NULLABLE\"),\n",
    "                    bigquery.SchemaField(\"retry_attempts\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "                ]\n",
    "            )\n",
    "            \n",
    "            # Load the batch\n",
    "            job = client.load_table_from_dataframe(batch_df, table_ref, job_config=job_config)\n",
    "            job.result()  # Wait for completion\n",
    "            \n",
    "            print(f\"   ‚úÖ Batch {batch_number} saved successfully!\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Error saving batch {batch_number}: {e}\")\n",
    "            # Don't stop the whole process for one batch failure\n",
    "\n",
    "def main_gemini_15_flash_evaluation():\n",
    "    \"\"\"\n",
    "    Main function to run Gemini 1.5 Flash evaluation on Meta dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"üöÄ STARTING GEMINI 1.5 FLASH JUDGE EVALUATION - FULL META DATASET\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    try:\n",
    "        # Initialize pipeline\n",
    "        pipeline = Gemini15FlashJudgePipeline()\n",
    "        \n",
    "        # Step 1: Load the complete Meta dataset\n",
    "        print(f\"\\nüìã Step 1: Loading complete Meta dataset...\")\n",
    "        meta_df = pipeline.load_full_meta_dataset()\n",
    "        \n",
    "        if meta_df.empty:\n",
    "            print(\"‚ùå No data loaded from Meta table\")\n",
    "            return None\n",
    "        \n",
    "        # Step 2: Test with one sample first\n",
    "        print(f\"\\nüß™ Step 2: Testing with one sample...\")\n",
    "        test_row = meta_df.iloc[0]\n",
    "        print(f\"   Testing Meta artifact: {test_row['artifact_id']}\")\n",
    "        \n",
    "        content = pipeline.load_artifact_content(test_row)\n",
    "        judge_result = pipeline.query_gemini_judge(\n",
    "            content, \n",
    "            test_row['model_prompt'], \n",
    "            test_row['correct_reasoning']\n",
    "        )\n",
    "        \n",
    "        if 'error' in judge_result:\n",
    "            print(f\"‚ùå Test failed: {judge_result['error']}\")\n",
    "            return None\n",
    "        else:\n",
    "            print(f\"‚úÖ Test successful!\")\n",
    "            print(f\"   Agreement: {judge_result.get('judge_agreement')}\")\n",
    "            print(f\"   Confidence: {judge_result.get('confidence')}\")\n",
    "            print(f\"   API time: {judge_result.get('api_time'):.2f}s\")\n",
    "        \n",
    "        # Step 3: Run evaluation on dataset\n",
    "        batch_size = 50  # Optimized batch size for full dataset\n",
    "        print(f\"\\nüîÑ Step 3: Running evaluation on {len(meta_df):,} records...\")\n",
    "        results_df = pipeline.run_full_dataset_evaluation(\n",
    "            meta_df, \n",
    "            batch_size=batch_size,\n",
    "            save_to_bigquery=True\n",
    "        )\n",
    "        \n",
    "        if results_df.empty:\n",
    "            print(\"‚ùå No evaluation results generated\")\n",
    "            return None\n",
    "        \n",
    "        # Step 4: Create summary report\n",
    "        print(f\"\\nüìÑ Step 4: Creating summary report...\")\n",
    "        \n",
    "        summary_report = {\n",
    "            'timestamp': pd.Timestamp.now().isoformat(),\n",
    "            'dataset_info': {\n",
    "                'source_table': f\"{PROJECT_ID}.{DATASET_ID}.{META_TABLE}\",\n",
    "                'results_table': f\"{PROJECT_ID}.{DATASET_ID}.{RESULTS_TABLE}\",\n",
    "                'total_records_processed': len(results_df),\n",
    "                'successful_evaluations': pipeline.successful_evaluations,\n",
    "                'failed_evaluations': pipeline.failed_evaluations,\n",
    "                'batch_size': batch_size\n",
    "            },\n",
    "            'model_info': {\n",
    "                'judge_model': GEMINI_MODEL_NAME,\n",
    "                'flash_model': 'gemini-flash',\n",
    "                'api_calls': pipeline.api_call_count,\n",
    "                'total_api_time': pipeline.total_api_time,\n",
    "                'total_input_tokens': pipeline.total_input_tokens,\n",
    "                'total_output_tokens': pipeline.total_output_tokens\n",
    "            },\n",
    "            'performance_metrics': {\n",
    "                'overall_agreement_rate': float(results_df['judge_agreement'].mean()),\n",
    "                'average_confidence': float(results_df['confidence'].mean()),\n",
    "                'classification_breakdown': dict(results_df['flash_classification'].value_counts()),\n",
    "                'agreement_by_classification': dict(\n",
    "                    results_df.groupby('flash_classification')['judge_agreement'].mean()\n",
    "                )\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Save summary to file\n",
    "        summary_filename = f\"gemini_15_flash_meta_summary_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "        with open(summary_filename, 'w') as f:\n",
    "            json.dump(summary_report, f, indent=2, default=str)\n",
    "        \n",
    "        print(f\"‚úÖ Summary report saved to: {summary_filename}\")\n",
    "        \n",
    "        # Final success message\n",
    "        print(f\"\\nüéâ GEMINI 1.5 FLASH JUDGE EVALUATION COMPLETED SUCCESSFULLY!\")\n",
    "        print(f\"üìä Total records processed: {len(results_df):,}\")\n",
    "        print(f\"üìä Overall agreement rate: {results_df['judge_agreement'].mean():.1%}\")\n",
    "        print(f\"üìä API calls made: {pipeline.api_call_count:,}\")\n",
    "        print(f\"üíæ Results saved to: {PROJECT_ID}.{DATASET_ID}.{RESULTS_TABLE}\")\n",
    "        print(f\"üìÑ Summary report: {summary_filename}\")\n",
    "        \n",
    "        # Show final query to view results\n",
    "        print(f\"\\nüîç QUERY TO VIEW RESULTS:\")\n",
    "        print(f\"SELECT * FROM `{PROJECT_ID}.{DATASET_ID}.{RESULTS_TABLE}` ORDER BY created_at DESC LIMIT 100\")\n",
    "        \n",
    "        return results_df, summary_report\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå GEMINI 1.5 FLASH EVALUATION FAILED: {type(e).__name__}: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return None, None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run the evaluation on FULL META DATASET with Gemini 1.5 Flash\n",
    "    print(\"üöÄ RUNNING FULL META DATASET EVALUATION WITH GEMINI 1.5 FLASH\")\n",
    "    print(\"Enhanced with robust retry logic and cleaned schema\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Run full Meta dataset evaluation\n",
    "    results, summary = main_gemini_15_flash_evaluation()\n",
    "    \n",
    "    if results is not None:\n",
    "        print(f\"\\n‚úÖ FULL Meta dataset evaluation completed successfully!\")\n",
    "        print(f\"üìä {len(results):,} evaluations completed\")\n",
    "        print(f\"üìä Agreement rate: {results['judge_agreement'].mean():.1%}\")\n",
    "        print(f\"üìä Average retry attempts: {results.get('retry_attempts', pd.Series([1])).mean():.1f}\")\n",
    "    else:\n",
    "        print(f\"\\n‚ùå FULL Meta dataset evaluation failed - check error messages above\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dceb1e2d",
   "metadata": {},
   "source": [
    "Web data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c40d45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "BigQuery Pipeline with Gemini 1.5 Flash Judge - Web Dataset\n",
    "Uses Gemini 1.5 Flash to evaluate Gemini Flash decisions on Web dataset\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "from google.oauth2 import service_account\n",
    "import google.generativeai as genai\n",
    "from google.generativeai.types import HarmCategory, HarmBlockThreshold\n",
    "import json\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Any, Optional\n",
    "import traceback\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "import re\n",
    "import io\n",
    "from PIL import Image\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv('.env')\n",
    "\n",
    "# Configuration for Web dataset with Gemini 1.5 Flash\n",
    "PROJECT_ID = \"scope3-dev\"\n",
    "DATASET_ID = \"research_bs_monitoring\"\n",
    "WEB_TABLE = \"BA_Web_Ground_Truth\"  # Web ground truth table\n",
    "RESULTS_TABLE = \"BA_Web_Gemini_15_Flash_Judge_Results\"  # Results table for Gemini 1.5 Flash\n",
    "RESEARCH_BUCKET = os.getenv('RESEARCH_BUCKET', 'classification-research')\n",
    "GEMINI_MODEL_NAME = \"gemini-1.5-flash\"  # Gemini 1.5 Flash model\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "# Configure Gemini 1.5 Flash\n",
    "if GEMINI_API_KEY:\n",
    "    genai.configure(api_key=GEMINI_API_KEY)\n",
    "    print(\"‚úÖ Gemini 1.5 Flash configured successfully!\")\n",
    "else:\n",
    "    print(\"‚ùå ERROR: Please set your GEMINI_API_KEY environment variable\")\n",
    "    exit(1)\n",
    "\n",
    "# Initialize BigQuery client\n",
    "def initialize_bigquery_client() -> bigquery.Client:\n",
    "    \"\"\"Initialize BigQuery client with proper error handling\"\"\"\n",
    "    try:\n",
    "        client = bigquery.Client(project=PROJECT_ID)\n",
    "        \n",
    "        # Test the connection immediately\n",
    "        print(f\"üîß Testing BigQuery connection to {PROJECT_ID}...\")\n",
    "        \n",
    "        # Verify we can access the dataset\n",
    "        dataset = client.get_dataset(f\"{PROJECT_ID}.{DATASET_ID}\")\n",
    "        print(f\"‚úÖ BigQuery connection successful!\")\n",
    "        print(f\"   Project: {PROJECT_ID}\")\n",
    "        print(f\"   Dataset: {dataset.dataset_id}\")\n",
    "        print(f\"   Location: {dataset.location}\")\n",
    "        \n",
    "        return client\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå BigQuery initialization failed: {type(e).__name__}: {e}\")\n",
    "        print(f\"\\nüí° Troubleshooting steps:\")\n",
    "        print(f\"   1. Run: gcloud auth application-default login\")\n",
    "        print(f\"   2. Verify project ID: {PROJECT_ID}\")\n",
    "        print(f\"   3. Verify dataset exists: {DATASET_ID}\")\n",
    "        print(f\"   4. Check BigQuery permissions (Data Editor, Job User)\")\n",
    "        raise\n",
    "\n",
    "# Initialize clients globally\n",
    "client = initialize_bigquery_client()\n",
    "\n",
    "try:\n",
    "    storage_client = storage.Client(project=PROJECT_ID)\n",
    "    print(\"‚úÖ Storage client initialized for GCS access\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Storage client failed: {e}\")\n",
    "    storage_client = None\n",
    "\n",
    "# Initialize Gemini model\n",
    "gemini_model = genai.GenerativeModel(GEMINI_MODEL_NAME)\n",
    "print(f\"‚úÖ {GEMINI_MODEL_NAME} model initialized\")\n",
    "\n",
    "class Gemini15FlashJudgePipeline:\n",
    "    \"\"\"Pipeline using Gemini 1.5 Flash to judge Gemini Flash decisions for Web dataset\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.api_call_count = 0\n",
    "        self.total_api_time = 0\n",
    "        self.total_input_tokens = 0\n",
    "        self.total_output_tokens = 0\n",
    "        self.successful_evaluations = 0\n",
    "        self.failed_evaluations = 0\n",
    "\n",
    "    def check_available_tables(self):\n",
    "        \"\"\"Check what tables are available in the dataset\"\"\"\n",
    "        try:\n",
    "            print(f\"üîç Checking available tables in {PROJECT_ID}.{DATASET_ID}...\")\n",
    "            \n",
    "            query = f\"\"\"\n",
    "            SELECT table_name, table_type, creation_time \n",
    "            FROM `{PROJECT_ID}.{DATASET_ID}.INFORMATION_SCHEMA.TABLES`\n",
    "            ORDER BY table_name\n",
    "            \"\"\"\n",
    "            \n",
    "            tables_df = client.query(query).to_dataframe()\n",
    "            print(f\"üìä Available tables:\")\n",
    "            for _, row in tables_df.iterrows():\n",
    "                print(f\"   - {row['table_name']} ({row['table_type']})\")\n",
    "            \n",
    "            return tables_df['table_name'].tolist()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Could not check tables: {e}\")\n",
    "            return []\n",
    "\n",
    "    def load_full_web_dataset(self, limit: int = None) -> pd.DataFrame:\n",
    "        \"\"\"Load Web dataset from BigQuery - Simplified without unused fields\"\"\"\n",
    "        \n",
    "        if limit:\n",
    "            print(f\"üì• Loading TEST Web dataset ({limit} records) from {PROJECT_ID}.{DATASET_ID}.{WEB_TABLE}...\")\n",
    "        else:\n",
    "            print(f\"üì• Loading COMPLETE Web dataset from {PROJECT_ID}.{DATASET_ID}.{WEB_TABLE}...\")\n",
    "        \n",
    "        # First, check available tables\n",
    "        available_tables = self.check_available_tables()\n",
    "        \n",
    "        # Simplified query using only Web table\n",
    "        limit_clause = f\"LIMIT {limit}\" if limit else \"\"\n",
    "        query = f\"\"\"\n",
    "        SELECT \n",
    "            artifact_id,\n",
    "            artifact_json_gcs_url,\n",
    "            model_prompt,\n",
    "            correct_classification,\n",
    "            correct_reasoning,\n",
    "            source,\n",
    "            '{WEB_TABLE}' as data_source\n",
    "        FROM `{PROJECT_ID}.{DATASET_ID}.{WEB_TABLE}`\n",
    "        ORDER BY artifact_id\n",
    "        {limit_clause}\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            print(f\"‚è≥ Executing query to load {'test' if limit else 'full'} Web dataset...\")\n",
    "            df = client.query(query).to_dataframe()\n",
    "            \n",
    "            if limit:\n",
    "                print(f\"‚úÖ Successfully loaded TEST Web dataset!\")\n",
    "                print(f\"üìä Test records: {len(df):,} (requested: {limit})\")\n",
    "            else:\n",
    "                print(f\"‚úÖ Successfully loaded COMPLETE Web dataset!\")\n",
    "                print(f\"üìä Total records: {len(df):,}\")\n",
    "            \n",
    "            print(f\"üìä Classification distribution: {df['correct_classification'].value_counts().to_dict()}\")\n",
    "            print(f\"üìä Source distribution: {df['source'].value_counts().to_dict()}\")\n",
    "            print(f\"üìä Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n",
    "            \n",
    "            return df\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading {'test' if limit else 'full'} Web dataset: {type(e).__name__}: {e}\")\n",
    "            raise\n",
    "\n",
    "    def extract_gcs_path(self, url: str) -> tuple:\n",
    "        \"\"\"Extract bucket name and path from GCS URL\"\"\"\n",
    "        try:\n",
    "            if not isinstance(url, str) or url == 'nan' or not url.strip():\n",
    "                return None, None\n",
    "            \n",
    "            # Check for pandas NaN    \n",
    "            if pd.isna(url):\n",
    "                return None, None\n",
    "                \n",
    "            # Match gs://bucket-name/path format\n",
    "            match = re.match(r\"gs://([^/]+)/(.+)\", url.strip())\n",
    "            if match:\n",
    "                return match.group(1), match.group(2)\n",
    "            return None, None\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting GCS path from {url}: {e}\")\n",
    "            return None, None\n",
    "\n",
    "    def read_json_from_gcs(self, bucket_name: str, json_path: str) -> Optional[Dict]:\n",
    "        \"\"\"Read JSON artifact from GCS bucket\"\"\"\n",
    "        try:\n",
    "            bucket = storage_client.bucket(bucket_name)\n",
    "            blob = bucket.blob(json_path)\n",
    "            \n",
    "            if not blob.exists():\n",
    "                print(f\"JSON file not found: gs://{bucket_name}/{json_path}\")\n",
    "                return None\n",
    "                \n",
    "            json_content = blob.download_as_text()\n",
    "            return json.loads(json_content)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading JSON from GCS: {e}\")\n",
    "            return None\n",
    "\n",
    "    def load_artifact_content(self, row):\n",
    "        \"\"\"Load artifact content with retry logic\"\"\"\n",
    "        if not storage_client:\n",
    "            print(f\"‚ö†Ô∏è No storage client, using demo content for {row['artifact_id']}\")\n",
    "            return self.create_demo_content()\n",
    "        \n",
    "        max_retries = 3\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                # Try to load from artifact_json_gcs_url (primary method for Web table)\n",
    "                if pd.notna(row.get('artifact_json_gcs_url')):\n",
    "                    gcs_url = row['artifact_json_gcs_url']\n",
    "                    if attempt == 0:\n",
    "                        print(f\"üì• Loading Web content from GCS URL: {gcs_url}\")\n",
    "                    \n",
    "                    bucket_name, json_path = self.extract_gcs_path(gcs_url)\n",
    "                    if bucket_name and json_path:\n",
    "                        content = self.read_json_from_gcs(bucket_name, json_path)\n",
    "                        if content:\n",
    "                            if attempt == 0:\n",
    "                                print(f\"‚úÖ Successfully loaded Web content for {row['artifact_id']}\")\n",
    "                            return content\n",
    "                        else:\n",
    "                            if attempt < max_retries - 1:\n",
    "                                print(f\"‚ö†Ô∏è Attempt {attempt + 1} failed to load Web JSON, retrying...\")\n",
    "                                time.sleep(1)  # Brief pause before retry\n",
    "                                continue\n",
    "                    else:\n",
    "                        print(f\"‚ö†Ô∏è Could not parse Web GCS URL: {gcs_url}\")\n",
    "                        break\n",
    "                \n",
    "                # If all retries fail, use demo content\n",
    "                if attempt == max_retries - 1:\n",
    "                    print(f\"‚ö†Ô∏è All {max_retries} attempts failed for {row['artifact_id']}, using demo content\")\n",
    "                    return self.create_demo_content()\n",
    "                    \n",
    "            except Exception as e:\n",
    "                if attempt < max_retries - 1:\n",
    "                    print(f\"‚ö†Ô∏è Attempt {attempt + 1} failed for {row['artifact_id']}: {e}, retrying...\")\n",
    "                    time.sleep(1)\n",
    "                    continue\n",
    "                else:\n",
    "                    print(f\"‚ö†Ô∏è All retries failed for {row['artifact_id']}: {e}, using demo content\")\n",
    "                    return self.create_demo_content()\n",
    "        \n",
    "        return self.create_demo_content()\n",
    "    \n",
    "    def create_demo_content(self):\n",
    "        \"\"\"Create demo content when GCS loading fails\"\"\"\n",
    "        return {\n",
    "            \"url\": \"https://example.com/content\",\n",
    "            \"text_content\": [\n",
    "                {\n",
    "                    \"type\": \"heading\",\n",
    "                    \"heading\": {\"level\": 1, \"text\": \"Sample Content\"}\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"paragraph\", \n",
    "                    \"paragraphs\": [\n",
    "                        \"This is sample content for demonstration purposes.\",\n",
    "                        \"It represents the type of content that would be evaluated for brand safety.\"\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    def extract_content_from_artifact(self, artifact_json: Dict) -> Dict[str, any]:\n",
    "        \"\"\"Extract text and image content from artifact JSON\"\"\"\n",
    "        content = {\n",
    "            'text_content': '',\n",
    "            'image_paths': [],\n",
    "            'has_image': False,\n",
    "            'content_type': 'unknown'\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            text_parts = []\n",
    "            \n",
    "            # Look for structured JSON content with text_content array (main approach)\n",
    "            text_content_array = artifact_json.get(\"text_content\", [])\n",
    "            if text_content_array and isinstance(text_content_array, list):\n",
    "                # Parse structured content\n",
    "                for content_item in text_content_array:\n",
    "                    if isinstance(content_item, dict):\n",
    "                        content_type = content_item.get(\"type\", \"\")\n",
    "                        \n",
    "                        if content_type == \"paragraph\":\n",
    "                            paragraphs = content_item.get(\"paragraphs\", [])\n",
    "                            if paragraphs:\n",
    "                                text_parts.extend(paragraphs)\n",
    "                        \n",
    "                        elif content_type == \"image\":\n",
    "                            image_data = content_item.get(\"image\", {})\n",
    "                            if isinstance(image_data, dict):\n",
    "                                image_identifier = image_data.get(\"filepath\", \"\")\n",
    "                                if image_identifier:\n",
    "                                    content['image_paths'].append(image_identifier)\n",
    "                                    content['has_image'] = True\n",
    "                                \n",
    "                                # Also extract alt_text for context\n",
    "                                alt_text = image_data.get(\"alt_text\", \"\")\n",
    "                                if alt_text:\n",
    "                                    text_parts.append(f\"[Image: {alt_text}]\")\n",
    "                        \n",
    "                        elif content_type == \"video\":\n",
    "                            video_data = content_item.get(\"video\", {})\n",
    "                            if isinstance(video_data, dict):\n",
    "                                frames = video_data.get(\"frames\", [])\n",
    "                                if frames and len(frames) > 0:\n",
    "                                    # Use first frame as representative image\n",
    "                                    first_frame = frames[0] if isinstance(frames[0], dict) else {}\n",
    "                                    frame_identifier = first_frame.get(\"filepath\", \"\")\n",
    "                                    if frame_identifier:\n",
    "                                        content['image_paths'].append(frame_identifier)\n",
    "                                        content['has_image'] = True\n",
    "                    \n",
    "                    elif isinstance(content_item, str):\n",
    "                        # Handle direct string content\n",
    "                        text_parts.append(content_item)\n",
    "            \n",
    "            # Fallback to legacy format if no structured content found\n",
    "            if not text_parts and not content['has_image']:\n",
    "                # Common text fields\n",
    "                for field in ['title', 'description', 'caption', 'text', 'content', 'body']:\n",
    "                    if field in artifact_json and artifact_json[field]:\n",
    "                        text_parts.append(str(artifact_json[field]))\n",
    "                \n",
    "                # Legacy image fields\n",
    "                legacy_content = artifact_json.get(\"text_content\", \"\")\n",
    "                if isinstance(legacy_content, str):\n",
    "                    text_parts.append(legacy_content)\n",
    "                    \n",
    "                    # Look for image identifiers in the text using regex - FIXED VERSION\n",
    "                    image_pattern = r'[a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{12}\\.(?:jpg|jpeg|png|webp|avif)'\n",
    "                    image_matches = re.findall(image_pattern, legacy_content)\n",
    "                    if image_matches:\n",
    "                        # Use the first full match (complete UUID + extension)\n",
    "                        content['image_paths'].append(image_matches[0])\n",
    "                        content['has_image'] = True\n",
    "                \n",
    "                # Platform-specific extraction\n",
    "                if 'platform_data' in artifact_json:\n",
    "                    platform_data = artifact_json['platform_data']\n",
    "                    if isinstance(platform_data, dict):\n",
    "                        for key, value in platform_data.items():\n",
    "                            if isinstance(value, str) and value.strip():\n",
    "                                text_parts.append(value)\n",
    "                \n",
    "                # Legacy image URL fields\n",
    "                image_fields = ['image_url', 'image_path', 'media_url', 'thumbnail_url']\n",
    "                for field in image_fields:\n",
    "                    if field in artifact_json and artifact_json[field]:\n",
    "                        content['image_paths'].append(artifact_json[field])\n",
    "                        content['has_image'] = True\n",
    "            \n",
    "            # Combine all text content\n",
    "            content['text_content'] = ' '.join(text_parts).strip()\n",
    "            \n",
    "            # Determine content type\n",
    "            if content['has_image'] and content['text_content']:\n",
    "                content['content_type'] = 'multimodal'\n",
    "            elif content['has_image']:\n",
    "                content['content_type'] = 'image_only'\n",
    "            elif content['text_content']:\n",
    "                content['content_type'] = 'text_only'\n",
    "            else:\n",
    "                content['content_type'] = 'no_content'\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting content: {e}\")\n",
    "        \n",
    "        return content\n",
    "\n",
    "    def extract_source_context(self, content):\n",
    "        \"\"\"Extract text content from artifact\"\"\"\n",
    "        extracted_content = self.extract_content_from_artifact(content)\n",
    "        return extracted_content['text_content'] if extracted_content['text_content'] else \"Sample content for evaluation\"\n",
    "\n",
    "    def query_gemini_judge(self, content, brand_prompt, gemini_flash_verdict):\n",
    "        \"\"\"Query Gemini 1.5 Flash with retry logic\"\"\"\n",
    "        max_retries = 3\n",
    "        base_delay = 1\n",
    "        \n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                # Extract text content using the same method as your pipeline\n",
    "                source_context = self.extract_source_context(content)\n",
    "                \n",
    "                # Create judge prompt - Gemini 1.5 Flash evaluating Gemini Flash\n",
    "                judge_prompt = f\"\"\"You are an expert content moderator using Gemini 1.5 Flash to evaluate another AI model's (Gemini Flash) brand safety decision.\n",
    "\n",
    "Use your reasoning capabilities to provide a thorough analysis of whether Gemini Flash made the right decision.\n",
    "\n",
    "BRAND GUIDELINES:\n",
    "{brand_prompt}\n",
    "\n",
    "CONTENT TO EVALUATE:\n",
    "{source_context[:2000]}{\"...\" if len(source_context) > 2000 else \"\"}\n",
    "\n",
    "GEMINI FLASH'S VERDICT:\n",
    "{gemini_flash_verdict}\n",
    "\n",
    "As Gemini 1.5 Flash, evaluate whether Gemini Flash's verdict is correct and well-reasoned. Consider:\n",
    "1. Accuracy of the classification given the brand guidelines\n",
    "2. Quality and completeness of the reasoning provided\n",
    "3. Any nuances or edge cases that Flash may have missed\n",
    "4. Whether you would reach the same conclusion\n",
    "\n",
    "Respond in JSON format:\n",
    "{{\n",
    "  \"judge_agreement\": true/false,\n",
    "  \"confidence\": 0.0-1.0,\n",
    "  \"verdict\": \"Aligned\" or \"Not-Aligned\",\n",
    "  \"reasoning\": \"Your detailed analysis as Gemini 1.5 Flash of why Flash's decision was correct or incorrect\",\n",
    "  \"improvements\": [\"suggestions for better reasoning if disagreeing\"],\n",
    "  \"flash_analysis\": \"analysis of Flash's performance on this content\"\n",
    "}}\"\"\"\n",
    "                \n",
    "                # Configure safety settings\n",
    "                safety_settings = {\n",
    "                    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "                    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "                    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "                    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "                }\n",
    "                \n",
    "                # Make API call with Gemini 1.5 Flash\n",
    "                start_time = time.time()\n",
    "                response = gemini_model.generate_content(\n",
    "                    judge_prompt,\n",
    "                    safety_settings=safety_settings\n",
    "                )\n",
    "                api_time = time.time() - start_time\n",
    "                \n",
    "                # Update tracking\n",
    "                self.api_call_count += 1\n",
    "                self.total_api_time += api_time\n",
    "                \n",
    "                # Track tokens if available\n",
    "                if hasattr(response, 'usage_metadata'):\n",
    "                    self.total_input_tokens += response.usage_metadata.prompt_token_count\n",
    "                    self.total_output_tokens += response.usage_metadata.candidates_token_count\n",
    "                \n",
    "                if response.text:\n",
    "                    result = self.parse_gemini_response(response.text, api_time)\n",
    "                    result['model_used'] = GEMINI_MODEL_NAME\n",
    "                    result['attempts'] = attempt + 1\n",
    "                    return result\n",
    "                else:\n",
    "                    if attempt < max_retries - 1:\n",
    "                        delay = base_delay * (2 ** attempt)  # Exponential backoff\n",
    "                        print(f\"‚ö†Ô∏è Empty response, retrying in {delay}s... (attempt {attempt + 1}/{max_retries})\")\n",
    "                        time.sleep(delay)\n",
    "                        continue\n",
    "                    else:\n",
    "                        return {\n",
    "                            'error': f'Empty response from {GEMINI_MODEL_NAME} after {max_retries} attempts',\n",
    "                            'model_used': GEMINI_MODEL_NAME,\n",
    "                            'api_time': api_time,\n",
    "                            'attempts': max_retries\n",
    "                        }\n",
    "                        \n",
    "            except Exception as e:\n",
    "                if attempt < max_retries - 1:\n",
    "                    delay = base_delay * (2 ** attempt)  # Exponential backoff\n",
    "                    print(f\"‚ö†Ô∏è API error: {str(e)[:100]}..., retrying in {delay}s... (attempt {attempt + 1}/{max_retries})\")\n",
    "                    time.sleep(delay)\n",
    "                    continue\n",
    "                else:\n",
    "                    return {\n",
    "                        'error': f'Failed after {max_retries} attempts: {str(e)}',\n",
    "                        'model_used': GEMINI_MODEL_NAME,\n",
    "                        'api_time': 0,\n",
    "                        'attempts': max_retries\n",
    "                    }\n",
    "        \n",
    "        # Should never reach here, but just in case\n",
    "        return {\n",
    "            'error': f'Unexpected failure after {max_retries} attempts',\n",
    "            'model_used': GEMINI_MODEL_NAME,\n",
    "            'api_time': 0,\n",
    "            'attempts': max_retries\n",
    "        }\n",
    "\n",
    "    def parse_gemini_response(self, response_text, api_time):\n",
    "        \"\"\"Parse Gemini 1.5 Flash response\"\"\"\n",
    "        try:\n",
    "            # Clean the response - remove markdown code blocks if present\n",
    "            cleaned_text = response_text.strip()\n",
    "            if cleaned_text.startswith('```json'):\n",
    "                cleaned_text = cleaned_text.replace('```json', '').replace('```', '').strip()\n",
    "            elif cleaned_text.startswith('```'):\n",
    "                cleaned_text = cleaned_text.replace('```', '').strip()\n",
    "            \n",
    "            # Try to find JSON in response\n",
    "            if '{' in cleaned_text and '}' in cleaned_text:\n",
    "                start_idx = cleaned_text.find('{')\n",
    "                end_idx = cleaned_text.rfind('}') + 1\n",
    "                json_str = cleaned_text[start_idx:end_idx]\n",
    "                \n",
    "                parsed = json.loads(json_str)\n",
    "                \n",
    "                # Ensure would_reach_same_conclusion is present\n",
    "                would_reach_same = parsed.get('would_reach_same_conclusion')\n",
    "                if would_reach_same is None:\n",
    "                    # Try to infer from the text if not explicitly provided\n",
    "                    full_text = response_text.lower()\n",
    "                    if any(phrase in full_text for phrase in ['same conclusion', 'reach the same', 'would also classify', 'independent conclusion']):\n",
    "                        would_reach_same = True\n",
    "                    elif any(phrase in full_text for phrase in ['different conclusion', 'would not reach', 'disagree with classification']):\n",
    "                        would_reach_same = False\n",
    "                    else:\n",
    "                        # Default to same as judge_agreement if unclear\n",
    "                        would_reach_same = parsed.get('judge_agreement', None)\n",
    "                \n",
    "                return {\n",
    "                    'judge_agreement': parsed.get('judge_agreement', None),\n",
    "                    'confidence': parsed.get('confidence', 0.0),\n",
    "                    'verdict': parsed.get('verdict', 'Unknown'),\n",
    "                    'would_reach_same_conclusion': would_reach_same,\n",
    "                    'reasoning': parsed.get('reasoning', ''),\n",
    "                    'improvements': parsed.get('improvements', []),\n",
    "                    'flash_analysis': parsed.get('flash_analysis', ''),\n",
    "                    'raw_response': response_text,\n",
    "                    'api_time': api_time\n",
    "                }\n",
    "            else:\n",
    "                # Fallback parsing\n",
    "                agreement = any(word in response_text.lower() for word in ['agree', 'correct', 'accurate'])\n",
    "                same_conclusion = any(phrase in response_text.lower() for phrase in [\n",
    "                    'same conclusion', 'reach the same', 'would also', 'independent conclusion'\n",
    "                ])\n",
    "                return {\n",
    "                    'judge_agreement': agreement,\n",
    "                    'confidence': 0.5,\n",
    "                    'verdict': 'Aligned' if agreement else 'Not-Aligned', \n",
    "                    'would_reach_same_conclusion': same_conclusion if same_conclusion else agreement,\n",
    "                    'reasoning': response_text,\n",
    "                    'improvements': [],\n",
    "                    'flash_analysis': '',\n",
    "                    'raw_response': response_text,\n",
    "                    'api_time': api_time\n",
    "                }\n",
    "                \n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"‚ö†Ô∏è JSON parsing failed: {e}\")\n",
    "            print(f\"Raw text: {response_text[:200]}...\")\n",
    "            \n",
    "            agreement = any(word in response_text.lower() for word in ['agree', 'reasonable'])\n",
    "            # Try to infer would_reach_same_conclusion from text\n",
    "            same_conclusion = any(phrase in response_text.lower() for phrase in [\n",
    "                'same conclusion', 'reach the same', 'would also', 'agree with the verdict'\n",
    "            ])\n",
    "            return {\n",
    "                'judge_agreement': agreement,\n",
    "                'would_reach_same_conclusion': same_conclusion if same_conclusion else agreement,\n",
    "                'confidence': 0.5,\n",
    "                'verdict': 'Aligned' if agreement else 'Not-Aligned',\n",
    "                'reasoning': response_text,\n",
    "                'improvements': [],\n",
    "                'flash_analysis': '',\n",
    "                'raw_response': response_text,\n",
    "                'api_time': api_time\n",
    "            }\n",
    "\n",
    "    def run_full_dataset_evaluation(self, web_df: pd.DataFrame, \n",
    "                                   batch_size: int = 100,\n",
    "                                   save_to_bigquery: bool = True) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Run Gemini 1.5 Flash evaluation on the COMPLETE Web dataset\n",
    "        \"\"\"\n",
    "        \n",
    "        print(f\"üîÑ RUNNING GEMINI 1.5 FLASH EVALUATION ON FULL WEB DATASET\")\n",
    "        print(\"=\" * 70)\n",
    "        print(f\"üìä Total records to process: {len(web_df):,}\")\n",
    "        print(f\"üì¶ Batch size: {batch_size:,}\")\n",
    "        print(f\"üì¶ Number of batches: {(len(web_df) + batch_size - 1) // batch_size}\")\n",
    "        print(f\"üß† Judge model: {GEMINI_MODEL_NAME}\")\n",
    "        print(f\"‚ö° Flash model: Gemini Flash (from ground truth)\")\n",
    "        \n",
    "        # Initialize results storage\n",
    "        all_results = []\n",
    "        \n",
    "        # Process in batches\n",
    "        for batch_num in range(0, len(web_df), batch_size):\n",
    "            batch_end = min(batch_num + batch_size, len(web_df))\n",
    "            batch_df = web_df.iloc[batch_num:batch_end].copy()\n",
    "            \n",
    "            batch_number = (batch_num // batch_size) + 1\n",
    "            total_batches = (len(web_df) + batch_size - 1) // batch_size\n",
    "            \n",
    "            print(f\"\\nüîÑ Processing Batch {batch_number}/{total_batches}\")\n",
    "            print(f\"   Records: {batch_num + 1:,} to {batch_end:,}\")\n",
    "            print(f\"   Batch size: {len(batch_df):,}\")\n",
    "            \n",
    "            batch_start_time = time.time()\n",
    "            batch_results = []\n",
    "            batch_successful = 0\n",
    "            batch_failed = 0\n",
    "            \n",
    "            # Process each record in the batch with progress bar\n",
    "            for idx, row in tqdm(batch_df.iterrows(), total=len(batch_df), \n",
    "                               desc=f\"Batch {batch_number}\", leave=False):\n",
    "                \n",
    "                try:\n",
    "                    # Load artifact content using updated method\n",
    "                    content = self.load_artifact_content(row)\n",
    "                    \n",
    "                    # Get Gemini 1.5 Flash judgment of Flash's decision\n",
    "                    judge_result = self.query_gemini_judge(\n",
    "                        content, \n",
    "                        row['model_prompt'], \n",
    "                        row['correct_reasoning']\n",
    "                    )\n",
    "                    \n",
    "                    # Create result record\n",
    "                    result = {\n",
    "                        'artifact_id': str(row['artifact_id']),\n",
    "                        'data_source': str(row['data_source']),\n",
    "                        'source': str(row.get('source', 'unknown')),\n",
    "                        'flash_classification': int(row['correct_classification']),\n",
    "                        'flash_reasoning': str(row['correct_reasoning'])[:1000],  # Truncate for storage\n",
    "                        'model_prompt': str(row['model_prompt'])[:500],\n",
    "                        'judge_agreement': judge_result.get('judge_agreement', None),\n",
    "                        'verdict': str(judge_result.get('verdict', 'Unknown')),\n",
    "                        'confidence': float(judge_result.get('confidence', 0.0)),\n",
    "                        'would_reach_same_conclusion': judge_result.get('would_reach_same_conclusion', None),\n",
    "                        'reasoning': str(judge_result.get('reasoning', ''))[:1000],\n",
    "                        'flash_analysis': str(judge_result.get('flash_analysis', ''))[:500],\n",
    "                        'improvements': str('; '.join(judge_result.get('improvements', [])))[:500],\n",
    "                        'api_call_time': float(judge_result.get('api_time', 0.0)),\n",
    "                        'batch_number': int(batch_number),\n",
    "                        'created_at': pd.Timestamp.now(),\n",
    "                        'model_used': str(judge_result.get('model_used', GEMINI_MODEL_NAME)),\n",
    "                        'error_message': str(judge_result.get('error', '')) if 'error' in judge_result else None,\n",
    "                        'retry_attempts': int(judge_result.get('attempts', 1))\n",
    "                    }\n",
    "                    \n",
    "                    batch_results.append(result)\n",
    "                    batch_successful += 1\n",
    "                    self.successful_evaluations += 1\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Error processing {row['artifact_id']}: {e}\")\n",
    "                    batch_failed += 1\n",
    "                    self.failed_evaluations += 1\n",
    "                    continue\n",
    "            \n",
    "            batch_time = time.time() - batch_start_time\n",
    "            \n",
    "            # Calculate batch statistics\n",
    "            if batch_results:\n",
    "                batch_agreement_rate = sum(1 for r in batch_results \n",
    "                                         if r['judge_agreement'] is True) / len(batch_results)\n",
    "                batch_avg_confidence = np.mean([r['confidence'] for r in batch_results \n",
    "                                              if r['confidence'] > 0])\n",
    "            else:\n",
    "                batch_agreement_rate = 0\n",
    "                batch_avg_confidence = 0\n",
    "            \n",
    "            print(f\"   ‚úÖ Batch {batch_number} completed in {batch_time:.1f}s\")\n",
    "            print(f\"   üìä Successful: {batch_successful}, Failed: {batch_failed}\")\n",
    "            print(f\"   üìä Agreement rate: {batch_agreement_rate:.1%}\")\n",
    "            print(f\"   üìä Avg confidence: {batch_avg_confidence:.2f}\")\n",
    "            print(f\"   üìä API calls: {self.api_call_count}\")\n",
    "            \n",
    "            # Add batch results to overall results\n",
    "            all_results.extend(batch_results)\n",
    "            \n",
    "            # Save batch to BigQuery if requested\n",
    "            if save_to_bigquery and len(batch_results) > 0:\n",
    "                self.save_batch_to_bigquery(pd.DataFrame(batch_results), batch_number)\n",
    "        \n",
    "        # Convert all results to DataFrame\n",
    "        results_df = pd.DataFrame(all_results)\n",
    "        \n",
    "        # Final statistics\n",
    "        final_agreement_rate = results_df['judge_agreement'].mean() if len(results_df) > 0 else 0\n",
    "        final_avg_confidence = results_df['confidence'].mean() if len(results_df) > 0 else 0\n",
    "        total_api_time = results_df['api_call_time'].sum() if len(results_df) > 0 else 0\n",
    "        \n",
    "        print(f\"\\n‚úÖ GEMINI 1.5 FLASH EVALUATION COMPLETED!\")\n",
    "        print(f\"üìä Total records processed: {len(results_df):,}\")\n",
    "        print(f\"üìä Successful evaluations: {self.successful_evaluations}\")\n",
    "        print(f\"üìä Failed evaluations: {self.failed_evaluations}\")\n",
    "        print(f\"üìä Overall agreement rate: {final_agreement_rate:.1%}\")\n",
    "        print(f\"üìä Average confidence: {final_avg_confidence:.2f}\")\n",
    "        print(f\"üìä Total API calls: {self.api_call_count}\")\n",
    "        print(f\"üìä Total API time: {total_api_time:.1f}s ({total_api_time/60:.1f} minutes)\")\n",
    "        \n",
    "        # Cost estimation for Gemini 1.5 Flash (much cheaper than 2.5 Pro)\n",
    "        input_cost = self.total_input_tokens * 0.00000075  # Gemini 1.5 Flash pricing\n",
    "        output_cost = self.total_output_tokens * 0.0000015\n",
    "        total_cost = input_cost + output_cost\n",
    "        print(f\"üí∞ Estimated cost: ${total_cost:.4f}\")\n",
    "        print(f\"   Input tokens: {self.total_input_tokens:,} (${input_cost:.4f})\")\n",
    "        print(f\"   Output tokens: {self.total_output_tokens:,} (${output_cost:.4f})\")\n",
    "        \n",
    "        return results_df\n",
    "\n",
    "    def save_batch_to_bigquery(self, batch_df: pd.DataFrame, batch_number: int):\n",
    "        \"\"\"Save a batch of results to BigQuery with updated schema\"\"\"\n",
    "        print(f\"   üíæ Saving batch {batch_number} to BigQuery ({len(batch_df)} records)...\")\n",
    "        \n",
    "        try:\n",
    "            # Configure the load job\n",
    "            table_ref = f\"{PROJECT_ID}.{DATASET_ID}.{RESULTS_TABLE}\"\n",
    "            \n",
    "            job_config = bigquery.LoadJobConfig(\n",
    "                write_disposition=\"WRITE_APPEND\",  # Append data\n",
    "                create_disposition=\"CREATE_IF_NEEDED\",  # Create table if needed\n",
    "                schema=[\n",
    "                    bigquery.SchemaField(\"artifact_id\", \"STRING\", mode=\"REQUIRED\"),\n",
    "                    bigquery.SchemaField(\"data_source\", \"STRING\", mode=\"NULLABLE\"),\n",
    "                    bigquery.SchemaField(\"source\", \"STRING\", mode=\"NULLABLE\"),\n",
    "                    bigquery.SchemaField(\"flash_classification\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "                    bigquery.SchemaField(\"flash_reasoning\", \"STRING\", mode=\"NULLABLE\"),\n",
    "                    bigquery.SchemaField(\"model_prompt\", \"STRING\", mode=\"NULLABLE\"),\n",
    "                    bigquery.SchemaField(\"judge_agreement\", \"BOOLEAN\", mode=\"NULLABLE\"),\n",
    "                    bigquery.SchemaField(\"verdict\", \"STRING\", mode=\"NULLABLE\"),\n",
    "                    bigquery.SchemaField(\"confidence\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "                    bigquery.SchemaField(\"would_reach_same_conclusion\", \"BOOLEAN\", mode=\"NULLABLE\"),\n",
    "                    bigquery.SchemaField(\"reasoning\", \"STRING\", mode=\"NULLABLE\"),\n",
    "                    bigquery.SchemaField(\"flash_analysis\", \"STRING\", mode=\"NULLABLE\"),\n",
    "                    bigquery.SchemaField(\"improvements\", \"STRING\", mode=\"NULLABLE\"),\n",
    "                    bigquery.SchemaField(\"api_call_time\", \"FLOAT\", mode=\"NULLABLE\"),\n",
    "                    bigquery.SchemaField(\"batch_number\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "                    bigquery.SchemaField(\"created_at\", \"TIMESTAMP\", mode=\"NULLABLE\"),\n",
    "                    bigquery.SchemaField(\"model_used\", \"STRING\", mode=\"NULLABLE\"),\n",
    "                    bigquery.SchemaField(\"error_message\", \"STRING\", mode=\"NULLABLE\"),\n",
    "                    bigquery.SchemaField(\"retry_attempts\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "                ]\n",
    "            )\n",
    "            \n",
    "            # Load the batch\n",
    "            job = client.load_table_from_dataframe(batch_df, table_ref, job_config=job_config)\n",
    "            job.result()  # Wait for completion\n",
    "            \n",
    "            print(f\"   ‚úÖ Batch {batch_number} saved successfully!\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Error saving batch {batch_number}: {e}\")\n",
    "            # Don't stop the whole process for one batch failure\n",
    "\n",
    "def main_gemini_15_flash_evaluation():\n",
    "    \"\"\"\n",
    "    Main function to run Gemini 1.5 Flash evaluation on Web dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"üöÄ STARTING GEMINI 1.5 FLASH JUDGE EVALUATION - FULL WEB DATASET\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    try:\n",
    "        # Initialize pipeline\n",
    "        pipeline = Gemini15FlashJudgePipeline()\n",
    "        \n",
    "        # Step 1: Load the complete Web dataset\n",
    "        print(f\"\\nüìã Step 1: Loading complete Web dataset...\")\n",
    "        web_df = pipeline.load_full_web_dataset()\n",
    "        \n",
    "        if web_df.empty:\n",
    "            print(\"‚ùå No data loaded from Web table\")\n",
    "            return None\n",
    "        \n",
    "        # Step 2: Test with one sample first\n",
    "        print(f\"\\nüß™ Step 2: Testing with one sample...\")\n",
    "        test_row = web_df.iloc[0]\n",
    "        print(f\"   Testing Web artifact: {test_row['artifact_id']}\")\n",
    "        \n",
    "        content = pipeline.load_artifact_content(test_row)\n",
    "        judge_result = pipeline.query_gemini_judge(\n",
    "            content, \n",
    "            test_row['model_prompt'], \n",
    "            test_row['correct_reasoning']\n",
    "        )\n",
    "        \n",
    "        if 'error' in judge_result:\n",
    "            print(f\"‚ùå Test failed: {judge_result['error']}\")\n",
    "            return None\n",
    "        else:\n",
    "            print(f\"‚úÖ Test successful!\")\n",
    "            print(f\"   Agreement: {judge_result.get('judge_agreement')}\")\n",
    "            print(f\"   Confidence: {judge_result.get('confidence')}\")\n",
    "            print(f\"   API time: {judge_result.get('api_time'):.2f}s\")\n",
    "        \n",
    "        # Step 3: Run evaluation on dataset\n",
    "        batch_size = 50  # Optimized batch size for full dataset\n",
    "        print(f\"\\nüîÑ Step 3: Running evaluation on {len(web_df):,} records...\")\n",
    "        results_df = pipeline.run_full_dataset_evaluation(\n",
    "            web_df, \n",
    "            batch_size=batch_size,\n",
    "            save_to_bigquery=True\n",
    "        )\n",
    "        \n",
    "        if results_df.empty:\n",
    "            print(\"‚ùå No evaluation results generated\")\n",
    "            return None\n",
    "        \n",
    "        # Step 4: Create summary report\n",
    "        print(f\"\\nüìÑ Step 4: Creating summary report...\")\n",
    "        \n",
    "        summary_report = {\n",
    "            'timestamp': pd.Timestamp.now().isoformat(),\n",
    "            'dataset_info': {\n",
    "                'source_table': f\"{PROJECT_ID}.{DATASET_ID}.{WEB_TABLE}\",\n",
    "                'results_table': f\"{PROJECT_ID}.{DATASET_ID}.{RESULTS_TABLE}\",\n",
    "                'total_records_processed': len(results_df),\n",
    "                'successful_evaluations': pipeline.successful_evaluations,\n",
    "                'failed_evaluations': pipeline.failed_evaluations,\n",
    "                'batch_size': batch_size\n",
    "            },\n",
    "            'model_info': {\n",
    "                'judge_model': GEMINI_MODEL_NAME,\n",
    "                'flash_model': 'gemini-flash',\n",
    "                'api_calls': pipeline.api_call_count,\n",
    "                'total_api_time': pipeline.total_api_time,\n",
    "                'total_input_tokens': pipeline.total_input_tokens,\n",
    "                'total_output_tokens': pipeline.total_output_tokens\n",
    "            },\n",
    "            'performance_metrics': {\n",
    "                'overall_agreement_rate': float(results_df['judge_agreement'].mean()),\n",
    "                'average_confidence': float(results_df['confidence'].mean()),\n",
    "                'classification_breakdown': dict(results_df['flash_classification'].value_counts()),\n",
    "                'agreement_by_classification': dict(\n",
    "                    results_df.groupby('flash_classification')['judge_agreement'].mean()\n",
    "                )\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Save summary to file\n",
    "        summary_filename = f\"gemini_15_flash_web_summary_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "        with open(summary_filename, 'w') as f:\n",
    "            json.dump(summary_report, f, indent=2, default=str)\n",
    "        \n",
    "        print(f\"‚úÖ Summary report saved to: {summary_filename}\")\n",
    "        \n",
    "        # Final success message\n",
    "        print(f\"\\nüéâ GEMINI 1.5 FLASH JUDGE EVALUATION COMPLETED SUCCESSFULLY!\")\n",
    "        print(f\"üìä Total records processed: {len(results_df):,}\")\n",
    "        print(f\"üìä Overall agreement rate: {results_df['judge_agreement'].mean():.1%}\")\n",
    "        print(f\"üìä API calls made: {pipeline.api_call_count:,}\")\n",
    "        print(f\"üíæ Results saved to: {PROJECT_ID}.{DATASET_ID}.{RESULTS_TABLE}\")\n",
    "        print(f\"üìÑ Summary report: {summary_filename}\")\n",
    "        \n",
    "        # Show final query to view results\n",
    "        print(f\"\\nüîç QUERY TO VIEW RESULTS:\")\n",
    "        print(f\"SELECT * FROM `{PROJECT_ID}.{DATASET_ID}.{RESULTS_TABLE}` ORDER BY created_at DESC LIMIT 100\")\n",
    "        \n",
    "        return results_df, summary_report\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå GEMINI 1.5 FLASH EVALUATION FAILED: {type(e).__name__}: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return None, None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run the evaluation on FULL WEB DATASET with Gemini 1.5 Flash\n",
    "    print(\"üöÄ RUNNING FULL WEB DATASET EVALUATION WITH GEMINI 1.5 FLASH\")\n",
    "    print(\"Enhanced with robust retry logic and cleaned schema\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Run full Web dataset evaluation\n",
    "    results, summary = main_gemini_15_flash_evaluation()\n",
    "    \n",
    "    if results is not None:\n",
    "        print(f\"\\n‚úÖ FULL Web dataset evaluation completed successfully!\")\n",
    "        print(f\"üìä {len(results):,} evaluations completed\")\n",
    "        print(f\"üìä Agreement rate: {results['judge_agreement'].mean():.1%}\")\n",
    "        print(f\"üìä Average retry attempts: {results.get('retry_attempts', pd.Series([1])).mean():.1f}\")\n",
    "    else:\n",
    "        print(f\"\\n‚ùå FULL Web dataset evaluation failed - check error messages above\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
